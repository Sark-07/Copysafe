{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    RobertaTokenizer,\n",
    "    RobertaModel,\n",
    "    XLNetTokenizer,\n",
    "    XLNetModel,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer,\n",
    ")\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics import f1_score\n",
    "from langdetect import detect\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to load and preprocess data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data = data[\"abstract\"].dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prime\\AppData\\Local\\Temp\\ipykernel_18456\\2076912401.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "source_data = load_and_preprocess_data(filepath=\"../dataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Background. The epidemiology of pediatric febrile illness is shifting in sub-Saharan Africa, but malaria remains a major cause of childhood morbidity and mortality. The present study describes causes of febrile illness in hospitalized children in Ghana and aims to determine the burden of malaria coinfections and their association with parasite densities.\\nMethods. In a prospective study, children (aged ≥30 days and ≤15 years) with fever ≥38.0°C were recruited after admission to the pediatric ward of a primary hospital in Ghana. Malaria parasitemia was determined and blood, stool, urine, respiratory, and cerebrospinal fluid specimens were screened for parasitic, bacterial, and viral pathogens. Associations of Plasmodium densities with other pathogens were calculated.\\nResults. From November 2013 to April 2015, 1238 children were enrolled from 4169 admissions. A clinical/microbiological diagnosis could be made in 1109/1238 (90%) patients, with Plasmodium parasitemia (n = 728/1238 [59%]) being predominant. This was followed by lower respiratory tract infections/pneumonia (n = 411/1238 [34%]; among detected pathogens most frequently Streptococcus pneumoniae, n = 192/299 [64%]), urinary tract infections (n = 218/1238 [18%]; Escherichia coli, n = 21/32 [66%]), gastrointestinal infections (n = 210 [17%]; rotavirus, n = 32/97 [33%]), and invasive bloodstream infections (n = 62 [5%]; Salmonella species, n = 47 [76%]). In Plasmodium-infected children the frequency of lower respiratory tract, gastrointestinal, and bloodstream infections increased with decreasing parasite densities.\\nConclusions. In a hospital setting, the likelihood of comorbidity with a nonmalarial disease is inversely correlated with increasing blood levels of malaria parasites. Hence, parasite densities provide important information as an indicator for the probability of coinfection, in particular to guide antimicrobial medication.'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to generate document vector**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_vector(text, model, tokenizer, max_chunk_length=512, overlap=50):\n",
    "    # Tokenize the text into chunks with specified overlap\n",
    "    tokens = tokenizer.tokenize(\n",
    "        tokenizer.decode(tokenizer.encode(text, add_special_tokens=True))\n",
    "    )\n",
    "    chunks = [\n",
    "        tokens[i : i + max_chunk_length]\n",
    "        for i in range(0, len(tokens), max_chunk_length - overlap)\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty tensor to store the embeddings\n",
    "    embeddings = torch.zeros((1, len(tokens), model.config.hidden_size))\n",
    "\n",
    "    # Iterate through chunks and generate embeddings\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(chunk)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(torch.tensor([input_ids]))\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings[:, i : i + len(chunk), :] = last_hidden_states\n",
    "\n",
    "    # Average the embeddings over all tokens\n",
    "    document_vector = embeddings.mean(dim=1).squeeze().detach().numpy()\n",
    "    return document_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_document_vector(text, model, tokenizer, max_length=512, device=None):\n",
    "#     if device is None:\n",
    "#         device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#     # Move the model to the specified device\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Set the model to evaluation mode\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         # Tokenize the text\n",
    "#         input_ids = tokenizer.encode(\n",
    "#             text, add_special_tokens=True, truncation=True\n",
    "#         )\n",
    "\n",
    "#         # Truncate or pad to the specified max length\n",
    "#         input_ids = input_ids[:max_length]\n",
    "#         input_ids += [tokenizer.pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "#         # Move the input to the specified device\n",
    "#         input_ids = torch.tensor([input_ids]).to(device)\n",
    "\n",
    "#         # Generate document vector\n",
    "#         document_vector = model(input_ids)[0].mean(dim=1).squeeze().detach().cpu().numpy()\n",
    "\n",
    "#     return document_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to create vectors using BERT**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_bert_vectors(data, model, tokenizer):\n",
    "#     vectors = []\n",
    "#     for text in tqdm(data[:100]):\n",
    "#         vector = generate_document_vector(text, model, tokenizer)\n",
    "#         vectors.append(vector)\n",
    "#     return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_vectors(data, model, tokenizer, max_length=512, device=None):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Move the model to the specified device\n",
    "    model.to(device)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(data[:5000]):\n",
    "            # Tokenize and handle sequences longer than max_length\n",
    "            input_ids = tokenizer.encode(\n",
    "                text, add_special_tokens=True, max_length=max_length, truncation=True\n",
    "            )\n",
    "            input_ids = torch.tensor([input_ids]).to(device)\n",
    "\n",
    "            # Generate document vector\n",
    "            vector = model(input_ids)[0].mean(dim=1).squeeze().detach().cpu().numpy()\n",
    "            vectors.append(vector)\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to evaluate**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(document_vector, source_vectors, source_data, threshold):\n",
    "    similarity_scores = cosine_similarity([document_vector], source_vectors)\n",
    "\n",
    "    most_similar_index = np.argmax(similarity_scores[0])\n",
    "    most_similar_score = similarity_scores[0][most_similar_index]\n",
    "    most_similar_article = source_data[most_similar_index]\n",
    "\n",
    "    is_matched = most_similar_score > threshold\n",
    "\n",
    "    return [is_matched, most_similar_score, most_similar_article]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analysis(document, source_data, threshold):\n",
    "#     highest_bleu_score = 0\n",
    "#     most_similar_article = None\n",
    "#     is_plagiarism = False\n",
    "\n",
    "#     # Tokenize the candidate text as it's required for BLEU score calculation\n",
    "#     candidate_tokens = document.split()\n",
    "\n",
    "#     for source_text in source_data:\n",
    "#         # Tokenize the source text\n",
    "#         source_tokens = [source_text.split()]  # BLEU expects a list of tokenized reference texts\n",
    "\n",
    "#         # Calculate the BLEU score between candidate text and this source text\n",
    "#         bleu_score = sentence_bleu(source_tokens, candidate_tokens)\n",
    "\n",
    "#         # Update if this is the highest BLEU score so far and check against threshold\n",
    "#         if bleu_score > highest_bleu_score:\n",
    "#             highest_bleu_score = bleu_score\n",
    "#             most_similar_article = source_text\n",
    "#             is_plagiarism = bleu_score > threshold\n",
    "\n",
    "#     return [is_plagiarism, highest_bleu_score, most_similar_article]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to report results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(is_matched, similarity_scores, document, most_similar_article):\n",
    "    print(\"Analysis Results:\\n\")\n",
    "    print(f\"Similarity Score: {similarity_scores}\")\n",
    "    print(f\"Decision: {'Match Detected' if is_matched else 'No match Detected'}\")\n",
    "    print(f\"Article submitted: \\n{document}\")\n",
    "    if is_matched:\n",
    "        print(f\"Most Similar Article:\\n{most_similar_article}\")\n",
    "    else:\n",
    "        print(\"\\nNo evidence of similar document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Different Models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model and tokenizer\n",
    "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load sciBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "\n",
    "# Load Roberta model and tokenizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "\n",
    "# Load XLNet model and tokenizer\n",
    "# tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "# model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Source vector generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [42:02<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate vectors for source data\n",
    "source_vectors = create_bert_vectors(source_data, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save Embeddings**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"embeddings_sciBERT.pkl\", \"wb\") as f:\n",
    "    pickle.dump(source_vectors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Language Translation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(input_text, source_lang, target_lang):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
    "\n",
    "    # Load pre-trained translation model and tokenizer\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize and translate\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    translation_ids = model.generate(input_ids)\n",
    "\n",
    "    # Decode the translated text\n",
    "    translated_text = tokenizer.decode(translation_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Language**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_language(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang\n",
    "    except:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main function to run the checker**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_checker(document, threshold=0.9):\n",
    "    # Check language of the document\n",
    "    document_language = check_language(document)\n",
    "\n",
    "    # Translate non-English document to English for consistency\n",
    "    if document_language != \"en\":\n",
    "        document = translate_text(document, document_language, \"en\")\n",
    "\n",
    "    # Generate vector for the document\n",
    "\n",
    "    document_vector = generate_document_vector(document, model, tokenizer)\n",
    "\n",
    "\n",
    "    # Perform analysis\n",
    "\n",
    "    response = analysis(document_vector, source_vectors, source_data, threshold)\n",
    "    # response = analysis(document, source_data, threshold)\n",
    "\n",
    "\n",
    "    # Report results and get the decision dictionary\n",
    "\n",
    "    report_results(response[0], response[1], document, response[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run the checker**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Results:\n",
      "\n",
      "Similarity Score: 0.9515116214752197\n",
      "Decision: Match Detected\n",
      "Article submitted: \n",
      "House flies, Musca domestica L. (Diptera: Muscidae), were examined for their ability to harbor and transmit Newcastle disease virus (family Paramyxoviridae, genus Avulavirus, NDV) by using a mesogenic NDV strain. Laboratory-reared flies were experimentally exposed to NDV (Roakin strain) by allowing flies to imbibe an inoculum consisting of chicken embryo-propagated virus. NDV was detected in dissected crops and intestinal tissues from exposed flies for up to 96 and 24 h postexposure, respectively; no virus was detected in crops\n",
      "Most Similar Article:\n",
      "House flies, Musca domestica L. (Diptera: Muscidae), were examined for their ability to harbor and transmit Newcastle disease virus (family Paramyxoviridae, genus Avulavirus, NDV) by using a mesogenic NDV strain. Laboratory-reared flies were experimentally exposed to NDV (Roakin strain) by allowing flies to imbibe an inoculum consisting of chicken embryo-propagated virus. NDV was detected in dissected crops and intestinal tissues from exposed flies for up to 96 and 24 h postexposure, respectively; no virus was detected in crops and intestines of sham-exposed flies. The potential of the house fly to directly transmit NDV to live chickens was examined by placing 14-d-old chickens in contact with NDV-exposed house flies 2 h after flies consumed NDV inoculum. NDV-exposed house flies contained ≈10(4) 50% infectious doses (ID(50)) per fly, but no transmission of NDV was observed in chickens placed in contact with exposed flies at densities as high as 25 flies per bird. Subsequent dose–response studies demonstrated that oral exposure, the most likely route for fly-to-chicken transmission, required an NDV (Roakin) dose ≥10(6) ID(50). These results indicate that house flies are capable of harboring NDV (Roakin) but that they are poor vectors of the virus because they carry an insufficient virus titer to cause infection.\n"
     ]
    }
   ],
   "source": [
    "document_to_check = \"The Bhagavad Gita, a revered Hindu scripture, unfolds as a dialogue between Lord Krishna and the warrior prince Arjuna on the battlefield of Kurukshetra. Spanning 700 verses, it encapsulates profound teachings on duty (dharma), righteousness, and the path to spiritual realization. Krishna imparts wisdom on fulfilling one's responsibilities without attachment to the results, emphasizing the pursuit of selflessness and inner harmony. Themes of devotion, discipline, and the nature of existence resonate throughout, offering guidance on navigating life's moral dilemmas and achieving spiritual enlightenment. The Gita's timeless wisdom continues to inspire seekers on the quest for deeper understanding and purpose.\"\n",
    "run_checker(document_to_check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
